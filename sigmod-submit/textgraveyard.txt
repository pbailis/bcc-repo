

The past decade has seen increased tumult in the landscape of database
design: faced with increasing scale and requirements for always-on
operation, many service operators shifted away from traditional
database designs and semantics and towards alternatives offering
greater scalability, availability, and
performance~\cite{dynamo,bigtable,cassandra,brewer-base}. This trend
belies a \textit{fundamental} divide in the design space of database
systems: the need for synchronous coordination between concurrent
operations. On the one hand, ``strong'' data consistency (i.e., CAP
``CP''~\cite{gilbert-cap}) models such as the gold standard of
traditional database concurrency control---the serializable
transaction, guaranteeing ``single system image''
behavior~\cite{gray-virtues}---provide semantic guarantees that are
useful for programmers~\cite{bernstein-book}. However, these
``strong'' models require synchronous coordination across replicas in
order to provide a safe response, leading to provable unavailability
and increased latency, and, in a single-site context, possible stalls
during execution~\cite{pacelc}. In contrast, ``weak consistency''
(i.e., CAP ``AP'', or ``highly available''~\cite{gilbert-cap}) models
provide a subset of the semantic guarantees but do not require
synchronous coordination and therefore do not suffer from
unavailability or latency~\cite{hat-vldb}. The latter category of
models (and many of their implementations~\cite{swift}) defer
coordination until some future point~\cite{calm,consistency-borders}
and are therefore are perfectly scalable, even at the granularity of
an individual database record. However, in giving up semantic
guarantees, weak isolation models sacrifice intuitive programmability.

This provable trade-off between semantics and coordination leads
programmers to a difficult choice. On the one hand, many applications
cannot operate correctly without serializable or Snapshot Isolation
guarantees. However, on the other hand, many applications---whether
running on newfangled stores providing weak data consistency or under
traditional ``weak isolation'' guarantees~\cite{adya-isolation}---seem
to tolerate weaker guarantees. Ideally, users can choose the weakest
possible set of semantics and still maintain correctness, but this is
no easy task: programmers today must manually map their
application-level consistency concerns to low-level models expressed
via constructs like admissible traces of reads and writes. This in
turn requires developers to become experts in distributed data
consistency, weak isolation, and replication
protocols~\cite{consistency-borders}.

In this paper, we seek an alternative approach that allows users to
determine when it is provably \textit{necessary} to employ
coordination in order to maintain application-level
correctness. Foregoing synchronous coordination (and therefore
serializability) necessarily means that users will be exposed to
isolation \textit{anomalies} resulting from concurrent
access. Determining which anomalies matter to an application is
impossible if a database system has no knowledge of the
application. Accordingly, we consider a model in which users
explicitly provide the database with \textit{integrity constraints},
or predicates representing application-level consistency that should
always be satisfied by the database state. Given these constraints,
the database can determine which procedures will require synchronous
coordination and, often, which read/write data consistency and
isolation level each procedure requires. We prove that the
\textit{\fullnameconfluence} property
(\iconfluence)~\cite{obs-confluence}---informally, the ability to
merge isolated transaction executions without violating
constraints---is a necessary and sufficient condition for executing
with \cfreedom. While we believe that this is the first necessary and
sufficient condition for availability without coordination, our
results leverage several decades-old concepts from the database
literature, including semantics-based concurrency
control~\cite{sdd1,decomp-semantics,badrinath-semantics,garciamolina-semantics,korth-serializability}
synchronization for abstract data
types~\cite{herlihy-apologizing,weihl-thesis}, and nested atomic
transactions~\cite{atomictransactions}
(Section~\ref{sec:relatedwork}).

This theory provides a foundation for \textit{coordination-avoiding
  databases}: systems that coordinate only when necessary.  If a
coordination-avoiding database system coordinates, it is because
application consistency \textit{cannot} be guaranteed without doing
so. Accordingly, coordination-avoidance analysis directly captures the
scalability of a given application: an application with \cfreedom can
effectively scale infinitely with the addition of more machines, while
the degree to which conflicts are distributed directly determines an
application's ability to scale out and up. We pithily summarize the
philosophy of coordination-avoidance via two high-level principles:
\begin{introenumerate}
\item \textit{Let concurrency safely flourish}: if a user's operations
  are \iconfluent, they should be executed on separate copies of
  database state, without coordination.
\item \textit{Minimize the distribution (both in space and time) of
  conflicting operations}: if a user's operations do not commute,
  execute the conflicting sections while involving as few servers and
  with as short of a critical section as possible.
\end{introenumerate}
To illustrate the utility of these principles, we embody \iconfluence
analysis in a tiny language, \lang, and analyze applications for
\cfreedom. As a proof of concept, we analyze and implement the TPC-C
New-Order on a coordination-avoiding database prototype and achieve
linear scalability to over 1.8 million transactions per second on a
100-node EC2 cluster (nearly four times the current record held by
Oracle). Our prototype's competitive advantage is not due to
bleeding-edge performance-oriented engineering but is instead due to
theoretically-motivated, judicious use of coordination.

Overall, this paper attempts to improve distributed database
programmability by unifying industry trends with the collected wisdom
of the database community. We recognize the scalability advantages of
weakly consistent data stores but reconcile them with the
programmability benefits of maintaining traditional ACID Consistency
on behalf of application designers. In doing so, we place an
additional burden on programmers, who must either provide the database
with a complete and machine-interpretable specification of
application-level invariants or otherwise must perform analysis
themselves and manually label their transactions. For programmers that
wish to achieve their application's maximum scalability, we believe
that both of these alternatives are far preferable to the
state-of-the-art ad-hoc mapping from application-level ACID
Consistency to distributed data consistency models performed today. We
accordingly view this work as the first step in revisiting core
database concepts like query optimization, failure recovery, and data
layout in light of increased knowledge of application-level semantics.


\begin{table*}
\begin{tabular}{|c|c|c|}
\hline
Constraint & \iconfluent Operations & Non-\iconfluent Operations \\\hline
\texttt{PRIMARY KEY} & modifications without specified values & modification with values specified \\
\texttt{AUTOINCREMENT} & - & insertion \\
\texttt{FOREIGN KEY} & mutation with pairing & mutation without pairing, deletion\\
\texttt{!=, ==} & all operations & - \\
\texttt{<} & increment, modification & decrement \\
\texttt{>} & decrement, modification & increment\\\hline

\end{tabular}
\caption{\iconfluence for \lang.}
\label{table:invariants}
\end{table*}


\footnote{This problem is more traditional due to two
  reasons. First, it assumes a mechanism to execute several operations
  atomically (serially), which requires coordination; here, we have
  instead (largely) focused on determining when coordination is
  required at all. Second, this work typically (but not exclusively) reasons
  about concrete transaction executions rather than \textit{all}
  possible executions.}

\miniheadnostop{Why specify stored procedures?} Much of the database
literature assumes a model in which users execute arbitrary queries
composed of arbitrary groupings of operations that are not known in
advance. While this model is well suited to the manual traditional
data processing and data entry tasks envisioned by early database
pioneers (i.e., users sit at terminals and type in transactions one by
one), there are at least two reasons why stored procedures are an
appropriate choice today. First, the large query volumes driving
today's distributed database designs are overwhelmingly created by
machines, not humans. Indeed, individual procedure invocations may
differ, but the overall structure of a queries at scale are often
known in advance, whether encoded in SQL or, alternatively,
application logic in an application server or ORM system. Second,
eliminating humans from transaction processing loop reduces execution
time and therefore the impact of critical sections. Several well-known
serializable systems such as H-Store and VoltDB, Calvin, and Granola
all exploit this a-priori knowledge to great effect. It \textit{is}
possible to support general purpose read/write transactions on opaque
registers in our formalism, but the results are not likely to be
useful.\vspace{.5em}

In the case of partially
replicated databases, whereby no one server contains an entire copy of
database state, we say that a database does not require coordination
if, whenever a transaction can access a replica for each of its
operations, those replicas guarantee transactional availability for
the transaction without contacting another equivalent set of replicas.


---

Conway's Law: combinations of operations and invariants commute: e.g., all write, no read, all read, no write

----

Applying analysis to systems:

Building a custom language is exciting but ultimately has performance challenges

Today, most immediate impact: programmers can manually reason about their application constraints without thinking about low-level models like causality and eventual consistency; also, smarter datatypes in the database like commutative counters and so on...

Low bar for a ``BCC'' system: each sp invocation (transaction) comes annotated with labels for either commuting or, if not, next hop in cycle (it's possible to collapse hops, but not strictly necessary); DB still doesn't know anything about stored procedures or integrity constraints

High bar for ``BCC'' system: all sp known in advance, all integrity contstraints know in advance

Our prototype focuses on the low bar for now---the high bar ventures into the domain of specialized program analysis. As we discuss in FUTUREWORK, we've had success in building small languages to capture the requirements of EVALUATION but reserve a full discussion for future work.

---

Merge function

There are some dumb answers: merge = nil; merge = LHS

Some better answers:
``bag'' semantics, expose all versions -- hard for the programmer, but effectively what ``immutability'' argument is all about

---

SIMPLE LANGUAGE FOR ANALYSIS

What commutes?

for now, assume we have data types that are known in advance: blobs/strings, numbers, counters

assume: PKEY, FKEY, UNIQUE, AUTOINCREMENT, NOGAP, !=, <, >

COMMUTES: 

counter.inc() and >
counter.dec() and <

any kind of !=
FKEY

with nonce, PKEY insert without specifying key
AUTOINCREMENT not sequential

CONFLICTS:

AUTOINCREMENT with NOGAP (sequential)
counter.inc() and <
counter.dec() and >
DELETE and insert into FKEY column


DISCUSSION: not claiming completeness (at this point), but, for a
simple SQL-like interface, this is actually pretty easy to enumerate
and, for simple programs, check. recursive SQL and unbounded loops
face the same problems, but, for the queries we've looked at, not
horrible.


In this paper, we seek an alternative solution: allow the use of
coordination-free protocols whenever they are safe and only require
coordination when it is provably required to do so. Our goal is to let
users forego strong models like serializability whenever possible but
still maintain application correctness. Given a system that can only
reason about arbitrary operations on opaque read/write registers, this
is an impossible task: giving up serializability necessarily means
that users will be exposed to a range of isolation \textit{anomalies},
or artifacts due to concurrent data accesses. To understand which
anomalies are acceptable, we require application writers to inform the
database about their application's notions of correctness in the form
of declarative integrity constraints. This in turn allows the database
to perform the compilation from application-level concerns to
distributed coordination mechanisms like linearizable test-and-set and
eventually consistent writes.


The past decade has seen increasing tumult in the landscape of
mainstream distributed database design.  Faced with increasing scale
and requirements for always-on operation, many service operators
shifted away from traditional database designs and semantics. The gold
standard in traditional database concurrency control---the
serializable transaction, which guarantees ``single system
programmability'' over arbitrary read-write operations---was provably
unachievable under the Internet services' requirements for high
availability and low latency. Instead, operators largely forfeited
transactional semantics in favor of ``weak'' consistency models. As of
2013, the long-term impact of this movement is unclear: we have
recently seen a resurgence of interest in transactional models, with
considerable debate as to which of these semantics---or possibly
alternative semantics---will emerge victorious.

These shifts nonetheless underscored a more fundamental divide in the
design space of distributed databases: requirements for
coordination. The introduction of the CAP Theorem in 2000 exposed many
modern practitioners to the trade-offs between strength of semantic
guarantees and coordination. On the one hand, ``strong'' data
consistency (i.e., CAP ``CP'') models provide semantic guarantees that
require coordination across replicas, leading to unavailability and
increased latency. In contrast, ``weak consistency'' (i.e., CAP
``AP'', or ``highly available'') models provide a subset of the
semantic guarantees but do not require synchronous coordination and
therefore do not suffer from unavailability or latency. The latter
category of models (and many of their implementations) are perfectly
scalable, even at the granularity of an individual database
record---all coordination can be safely deferred until some future
point (and, under some models, forever). However, in giving up
semantic guarantees, weak isolation models sacrifice programmability.

Data store users today must choose between two options: accept
expensive coordination via strong semantics or, alternatively, reason
about whether low-level weak consistency primitives are sufficient for
their applications. As Gray and Reuter pithily summarize: ``engineers
can build distributed systems, but few users know how to program them
or have algorithms that use them.'' Programmers using modern, highly
scalable data stores are not only frequently exposed to various
isolation and data consistency anomalies but must, in many cases,
effectively become distributed systems experts in order to reason
about system behavior during communication delays, concurrency, and
failures. Moreover, as evidenced by the proliferation of ``polyglot
persistence'' and the introduction of optional linearizable operations
in traditionally weakly consistent data stores, applications need a
mix of strong and weak models. Managing this trade-off is in turn
challenging: with too much strong consistency, scalability will
unnecessarily suffer, while too little strong consistency may
sacrifice correctness.




We rigorously justify these simple intuitions with theory. The first
condition requires the notion of \textit{invariant commutativity},
which we show is a necessary and sufficient condition for distributed
execution without coordination. Using this mechanism, if users provide
the database with a set of stored procedures and declarative
invariants over database state, we can provably determine when
invariants might be violated. Unlike prior mechanisms, this only
requires the user to provide a single set of invariants, without pre-
and post-conditions for each transaction
(Section~\ref{sec:relatedwork}). However, When operations are not invariant
commutative, synchronous coordination is required, but this does not
mean that the \textit{entire} transaction requires synchronous
coordination. Rather, by analyzing conflicting operations within a
transaction---which we perform via a symbolic variant of transaction
chopping---and performing careful data layout, we can minimize
coordination. We largely focus on distributed execution, but these
techniques are also applicable to single-node databases (and their
``weak isolation'' models).

BCC exposes coordination requirements that are fundamental to a given
application.




, or commute---and providing
\textit{countersteps} to define appropriate compensation logic. Our
definition of semantic commutativity formalizes the notion of
compatibility sets at the level of individual transactions and across
replicas, with no requirement for users to specify countersteps. We
require users to specify the space of transactions they wish to
execute, obviating the need for user intervention via fine-grained
labeling of transaction types. As a final important distinction, while
Garcia-Molina assumes each transaction \textit{step} is executed
atomically (linearizably), this requires coordination across replicas,
so semantic commutativity explicitly accounts for (temporarily)
divergent copies of database state.

 Semantic commutativity
generalizes this notion to include all possible interleavings of a
known set of transactions. Garcia-Molina proposes the use of
compatibility sets describe valid interleavings of individual, atomic
(node-local) operations, while semantic commutativity analysis uses a
single invariant to describe interleavings across multiple
nodes. Garcia-Molina considers countersteps to roll back faulty
transactions. No requirement here for internode consistency
constraints. Open question: ``will performance really improve?'' here,
we show definiteively yes.

Degenerate form of Owecki-Gries ``interference freedom'', where each
transaction's pre-condition and post-condition are the same:
invariants are satisified. This is only possible because the database
is free to abort transactions whose committing would violate integrity
constraints. Accordingly, Owecki-Gries and related concurrent
verification techniques may prove useful in \textit{proving} invariant
commutativity but require modification to handle internal aborts and
multi-statement transactions. We are actively investigating these
techniques as we expand our BCC analysis.

Long history spanning distributed databases, long-running
transactions, and semantics-based concurrency control.


Another important distinction between BCC and related work on
increasing concurrency is that BCC analysis flags \textit{any}
possible non-commutative operation for coordination. This is
conservative---for example, two decrement operations may not actually
cause a negative bank account balance---but, given the possibility of
violation, replicas must coordinate. Prior research leveraged
commutativity as a basis for increasing
concurrency~\cite{herlihy-apologizing,
  weihl-thesis,predicatewise-serializability} for individual
transactions, requiring coordination (therefore sacrificing
availability and low latency) but increasing concurrency nonetheless.

parallelizing compilers~\cite{rinard-compiler}


Alternatively, can apologize (Sagas).  Here, we enforce invariants
without compensation code.

``Local Verification of Global Integrity Constraints in Distributed
Databases''

closely related to detection of weak conjunctive global predicates
(``possibly'', equivalent to $K_i$ local knowledge), symbolic variant
of




Slightly less expensive is to only execute potentially conflicting
operations serially: any side effects that do not conflict can be
applied. However, need to make sure that transaction does not cause
abort. So, resolve conflicts then atomically apply all effects in
transaction (via MAV/Read Atomic semantics), as in OCC.

Now give the straw-man of having more semantic information between
steps (i.e., non-modular decomposition).

So far, have assumed that side effects are pre-determined, but many
``conflicts'' can be avoided if executed serially. Consider
AUTOINCREMENT. Really just needs to be executed atomically. So, in
effect, just need to serialize those operations. Consider it a
modification \textit{intent}: $intent(read\_set) \rightarrow
\{\delta_1,\dots,\delta_n}$. Pretty straightforward now: can perform
  transaction chopping on read, write sets at runtime. Steps become:
  execute abortable updates, perform chopping, apply rest of the
  updates. Note that this is expensive, but we do not attempt to find
  an optimal solution (e.g., could coalesce the abortable updates with
  the chopping state, although the ``abort'' case Chopping resolves
  first). Instead, simply trying to find guidelines---practically
  apply them in the next section.

Of course, even chopping will be conservative, but the problem is
that, within a transaction, you want to violate invariants. Therefore,
two choices: be conservative or request more fine-grained assertional
semantics from the end user. Here, we consider the former strategy but
refer the interested reader to



Modular: holds over all possible conflicts
Non-modular: holds over transaction state; precondition goes beyond I

Coalesce transactions to minimize *residual* interference; but don't want to over-coalesce
Need to derive the ``weakest assertions''--find a ``maximally reduced proof'';
assertional concurrency control scheme for system checks each transaction

-----

If a set of stored procedures is not invariant commutative, it does
not necessarily mean that all procedures must be executed with
coordination. If a subset of a procedure's outputs conflict, only
those conflicts must be executed.

We construct an invariant-conflict graph as follows:

For each pair of procedures $p_1$, $p_2$ such that there exists a
database state $D$ such that $I(p_1(D)\rightarrow \Delta_1)$ and
$I(p_2(D)\rightarrow \Delta_2=\{\delta_{2,1},\dots\delta_{2,n}\})$ are
true but $I(p_1(D) \cup p_2(D))$ is false, add an edge between
$\delta_{1,i}$ and $\delta_{2,j}$ whenever $I(p_1(\Delta_1-\delta_{1,i})
\cup \Delta_2-\delta_{2,j})$ is true.

Conservative estimate: run all parts of transaction serially
Less conservative estimate: run conflicting parts serially

Even less conservative: distinguish between merges and aborts

Abortable conflicts: resolve serially
Mergeable conflict: resolve afterwards -- mutation as *intent*, not literal

1.) resolve aborts
2.) resolve mergeable conflicts
3.) apply the rest of transactions

\begin{theorem}

\end{theorem}
