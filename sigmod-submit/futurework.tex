
\section{Future Work}
\label{sec:discussion}

In this paper, we have focused on the problem of recognizing when it
is possible to avoid distributed coordination. In this section, we
discuss extensions to our approaches and outline areas for future
work.

\minihead{Avoiding conflicts} Once a potentially conflicting set of
subsequences is identified via \iconfluence analysis, how should the
conflict be avoided? Our system model is amenable to standard
backwards validation from optimistic concurrency
control~\cite{bernstein-book}, but a range of existing techniques from
the realm of traditional database systems such as
locking~\cite{gray-virtues} and pre-scheduling~\cite{calvin} are also
possible. The optimal choice of strategy---as is the case in all
concurrency control---is workload-dependent, hinting at an opportunity
for physical ``query planning'' in light of
coordination-avoidance. For example, in a producer-consumer scenario
with exactly-once consumption semantics, there are multiple strategies
for coordination: all producers could coordinate, or all consumers, or
a mix of the two. The correct choice depends on the physical location,
prevalence, and distribution of the producing and consuming
transactions. Revisiting heuristics- and statistics-based query
planning, specifically targeting physical layout, choice of
concurrency control, and recovery appears worthwhile. While recent
work has focused on reducing distributed transactions via intelligent
partitioning~\cite{schism}, we believe that this is only one aspect of
a larger optimization problem.

\minihead{Amortizing coordination} We have analyzed conflicts on a
per-transaction basis, but it is possible to amortize the overhead of
coordination across multiple transactions. For example, the Escrow
transaction method~\cite{escrow} reduces coordination by allocating a
``share'' of non-\iconfluent operations between multiple
processes. For example, in a bank account, a remaining balance of
$\$100$ might be divided between $5$ bank servers, such that each
server can dispense $\$20$ to users without requiring coordination to
enforce an invariant of non-negative bank account balances. If any
given server runs out of pre-allocated money, it can ask another
server to ``refresh'' its current supply by borrowing more. This
Escrow technique allows availability for otherwise non-\iconfluent
operations up until a pre-determined number of concurrent
operations. In the context of our \cfreedom analysis, this is
equivalent to limiting the branching factor of (equivalently, the
number of merges in) the execution trace to a (pre-determined)
constant factor: in the example above, the number of concurrent
withdrawals cannot exceed $5$ servers. We do not attempt a full
formalism here but believe that adopting both Escrow and alternative
time-, versioned-, and numerical- drift-based models~\cite{yu-conit}
is an area for worthwhile future work.

\minihead{Future system design} Given our formal grounding
\iconfluence and promising early results, what is the appropriate
system architecture for a coordination-avoiding database
\textit{system}? In our TPC-C proof-of-concept implementation, we
analyzed each transaction component for \iconfluence and implemented
it in a custom prototype: we would not expect this of a typical
end-user of a relational database today. Instead, users should be able
to express their invariants in a high-level language like SQL and the
system should be able to avoid and resolve conflicts without their
approval. Analysis tools could automatically inform system's conflict
resolution policies as suggested above; we believe this is feasible in
the near-term. This in turn raises several interesting design and
engineering challenges: for example, as new invariants are added, the
system must ensure that satisfiability is possible. While we have
focused on SQL, we might also consider the use of restricted,
\iconfluent operators (e.g., Bloom\textsuperscript{L}~\cite{blooml})
and more data types.

