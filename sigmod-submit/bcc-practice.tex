
\section{CATs: Theory to Practice}
\label{sec:bcc-practice}

Invariant commutativity as a basis for coordination exposes a
trade-off between the operations a user wishes to perform and the
semantic guarantees she wishes to guarantee about her data. At the
extremes, with either all reads or all writes, a user can guarantee
any invariant. However, the space between yields a spectrum of
possible invariant commutative guarantees. In this section, we make
this trade-off concrete via a simple language analysis, a discussion
of system and merge function design, and a discussion of several
related techniques through the lens of invariant commutativity.

\subsection{\lang: A Simple Example Language}

To illustrate the utility of invariant commutativity, we consider a
simple, informal language modeled after simple SQL DDL and stored
procedures, \lang. In \lang, users store data in collections of
\textit{rows}, grouping rows with equivalent, pre-defined
\textit{columns} into \textit{tables}. Each column can contain either
\textit{string}, \textit{numeric}, or \textit{counter}
datatype. Strings and numeric types contain arbitrary data (resp.,
numbers) and support arbitrary modification, while counters contain
numeric data and support algebraic operations (e.g.,
\textit{increment}, \textit{decrement}). Users declare arbitrary
functions over data in the form of \textit{procedures}, each of which
consists of a variable number of \textit{statements}. Statements take
the form of read (e.g., \textit{select}), write (e.g.,
\textit{insert}), or update (e.g., \textit{update}, \textit{increment}
for counters, \textit{delete}) operations.

In the spirit of Balanced Concurrency Control, \lang also requires
users to define \textit{invariants} over their tables that express
application-level consistency requirements. Many of these are borrowed
from SQL. First, a \textit{primary key} on columns $C_1 \dots C_n$ of
table \textit{T} requires that, there should only be one row matching
each distinct combination of possible values for the specified
columns. Second, a \textit{autoincrement} constraint on a primary key
of numeric type requires that numeric values be contiguous. Third, a
\textit{foreign key} on numeric column $C_f$ of table $T_f$
referencing another column $C_r$ (resident in a different table $T_r
\neq T_f$) dictates that, for each row in $T_f$, there should be at
least one row in $T_f$ whose value for $C_r$ matches that of
$C_r$. Unlike SQL, \lang adds additional constraints to each column:
\textit{not equals}, \textit{equals}, and, for numeric and counter
datatypes, \textit{less than}, \textit{greater than}, and
\textit{sum\_of} (the final representing an aggregate of multiple
other numeric columns).


\begin{table*}
\begin{tabular}{|c|c|c|}
\hline
Constraint & Commutative Operations & Non-Commutative Operations \\\hline
\texttt{PRIMARY KEY} & modifications without specified values & modification with values specified \\
\texttt{AUTOINCREMENT} & - & insertion \\
\texttt{FOREIGN KEY} & mutation with pairing & mutation without pairing, deletion\\
\texttt{!=, ==} & all operations & - \\
\texttt{<} & increment, modification & decrement \\
\texttt{>} & decrement, modification & increment\\\hline

\end{tabular}
\caption{Invariant commutativity for \lang.}
\label{table:invariants}
\end{table*}

With this simple (but expressive) language in mind, we can enumerate a
set of invariant commutative and non-commutative operations. We do not
claim that this enumeration is even near-complete or that \lang is
sufficiently expressive for all applications. However, as we will see
(Section~\ref{sec:evaluation}), it is surprisingly expressive for many.

Several operations are invariant commutative: any operation on columns
without constraints, increment (decrement) of counters without
\textit{less than} (\textit{greater than}) constraints, modification
of foreign key columns (provided $i.)$ a suitable remote data column
is read as part of the same transaction or $ii.)$ a suitable remote
data column is modified), and any (in-)equality constraints,
\textit{sum\_of} (with the same caveat as foreign key
constraints). Given cluster-wide unique ID generation (i.e., UUID or
via cluster membership), insertion into primary key columns without
autoincrement constraints (provided the columns are not specified by
the end user---e.g., ``give me a new ID'' versus ``insert this new
ID'') are also supported. In contrast, insertion of specified primary
keys, use of autoincrement, and \textit{less than} and \textit{greater
  than} for decrement and increment operations, respectively, are not
invariant commutative. Perhaps not surprisingly, all of these rules
can be checked by simple syntactic rules; we built a simple \lang
analysis tool that identifies all of the above constructs in addition
to limited support for conditional updates in several days.

\subsection{Dealing with Conflicts}


If a set of stored procedures is not invariant commutative, then
concurrently executing combination of the procedures might violate the
given integrity constraint. This requires coordination--but how much?

At one extreme, it is sufficient to perform (serial) mutual exclusion
between any possibly conflicting transactions. For instance, if
procedures $p_1$ and $p_2$ could conflict, then a system could execute
each under a serializable isolation level. This is expensive: for any
\textit{possible} conflicts, transactions will have to coordinate and
potentially block, even for operations in the transactions that do not
conflict.

We suggest an alternative: let transactions execute in isolation and
produce outputs, and then use optimistic concurrency control to check
whether any conflicting outputs were actually produced. This
validation step is possibly expensive, as \textit{every} possible
conflict must be checked. If $\delta_{i1}$ and $\delta_{j1}$ conflict,
any transaction producing either of these outputs must contact a
validator in order to check whether the corresponding conflicting
action has been performed. If so, we have two options. In the basic
case, the transaction must abort due to a would-be conflict of
integrity constraints. We call these updates \textit{abortable
  conflicts}. However, not all conflicts require aborting. For
example, a transaction that enforces that \textit{some} doctor is on
duty need not actually abort if an alternate doctor is actually on
staff. We model these \textit{non-abortable conflicts} as
mini-transactions---effectively, closures that operate atomically on
database state. In the doctor case, the mini-transaction might check
the table for an existing doctor and simply produce no new output. In
a less trivial case, a user might autoincrement an ID counter when
inserting a new row; conflicts require serialization, not aborts. Of
course, this problem of reducing conflicting operations introduces a
new set of challenges.

Fortunately, the problem of minimizing conflicts is
well-studied.\footnote{This problem is more traditional due to two
  reasons. First, assumes a mechanism to execute several operations
  atomically (serially), which requires coordination; here, we've
  already determined that we require coordination. Second, typically
  (but not exclusively) reasons about concrete transaction executions
  rather than \textit{all} possible executions.} The most advanced
techniques we have encountered are those of Bernstein and Lewis's
``Assertional Concurrency Control'' protocols, which decompose
transactions into minimally-sized atomic units that are subsequently
executed as to avoid pre-condition invalidation (cf. \textit{maximally
  reduced proofs} for non-modular transaction
decomposition~\cite{decomp-semantics}). To do so, they require
additional semantics about intermediate pre- and post-conditions for
each operation: this brings this research into the realm of
programming languages. We believe this is a worthwhile area for future
work, but, due to programmer burden, do not further consider these
techniques in this paper.

As a compromise, we consider a modified form of serial execution,
approximating that of the nested atomic transaction abstraction. We
perform chopping on mini-transactions, replacing write-write conflicts
with our conflict relation determined from invariant commutativity.



\subsection{Merge Functions}

Thus far, we have assumed a simple set representation for database
operations. This is convenient for proving properties about database
state as well as reasoning about the behavior of merge functions, but,
in practice, merges may be more complex. For example, for many
applications, it is impractical to retain all versions ever written to
the database. Instead, databases may wish to \textit{compact} these
versions to limit storage requirements. A simple compaction policy is
\textit{last writer wins}, whereby writes are assigned a timestamp and
only the highest-timestamped write to each time is retained. However,
improper use of last-writer wins can yield invariant-``consistent''
but functionally inconsistent results: consider, for example, a user
that wishes to ensure that no bank account has negative balance. If
using a simple numeric register, if two users each withdraw \$60 from
an account with \$100, a last-writer wins column might end up with
\$40 total. This can be prevented by adding an additional invariant
that states that account balances should reflect all additions and
removals from each account, but this is an arguably non-trivial
pitfall. Similar false negatives can be achieved with ``

We propose the use of abstract datatypes to avoid anomalies such as
the above. The bank account example is not technically incorrect, but
it reflects an incomplete specification of invariants.

---

Conway's Law: combinations of operations and invariants commute: e.g., all write, no read, all read, no write

----

Applying analysis to systems:

Building a custom language is exciting but ultimately has performance challenges

Today, most immediate impact: programmers can manually reason about their application constraints without thinking about low-level models like causality and eventual consistency; also, smarter datatypes in the database like commutative counters and so on...

Low bar for a ``BCC'' system: each sp invocation (transaction) comes annotated with labels for either commuting or, if not, next hop in cycle (it's possible to collapse hops, but not strictly necessary); DB still doesn't know anything about stored procedures or integrity constraints

High bar for ``BCC'' system: all sp known in advance, all integrity contstraints know in advance

Our prototype focuses on the low bar for now---the high bar ventures into the domain of specialized program analysis. As we discuss in FUTUREWORK, we've had success in building small languages to capture the requirements of EVALUATION but reserve a full discussion for future work.

---

Merge function

There are some dumb answers: merge = nil; merge = LHS

Some better answers:
``bag'' semantics, expose all versions -- hard for the programmer, but effectively what ``immutability'' argument is all about

---

SIMPLE LANGUAGE FOR ANALYSIS

What commutes?

for now, assume we have data types that are known in advance: blobs/strings, numbers, counters

assume: PKEY, FKEY, UNIQUE, AUTOINCREMENT, NOGAP, !=, <, >

COMMUTES: 

counter.inc() and >
counter.dec() and <

any kind of !=
FKEY

with nonce, PKEY insert without specifying key
AUTOINCREMENT not sequential

CONFLICTS:

AUTOINCREMENT with NOGAP (sequential)
counter.inc() and <
counter.dec() and >
DELETE and insert into FKEY column


DISCUSSION: not claiming completeness (at this point), but, for a
simple SQL-like interface, this is actually pretty easy to enumerate
and, for simple programs, check. recursive SQL and unbounded loops
face the same problems, but, for the queries we've looked at, not
horrible.

---
When are different models useful?

Reads-from: FKey constraints
Atomic multi-put: FKey constraints

Uniqueness: nonce generators
RYW: sticky available

unavailability:
recency guarantees: deadlines (in a HA sense)
linearizability: breaking update cycles

---
How does this relate to more ad-hoc techniques?

Escrow: similar to a rely-guarantee from those PL guys--amortize
communication in exchange for unavailability during boundary
conditions/rebalancing

Immutability: makes merge trivial (if you solve the naming issue!);
says Gray: reads are writes

CRDTs/CALM: guarantee deterministic convergence to reasonable value;
weak safety guarantees (e.g., garbage is not returned [cite THINAIR])
but otherwise not safe for general purpose reads; Bloom\^L allows
'peek' but violates monotonicity
