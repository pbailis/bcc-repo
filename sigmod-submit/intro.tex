
\section{Introduction}
\label{sec:intro}

The past decade has seen increased tumult in the landscape of database
design: faced with increasing scale and requirements for always-on
operation, many service operators shifted away from traditional
database designs and semantics and towards alternatives offering
greater scalability, availability, and
performance~\cite{dynamo,bigtable,cassandra,brewer-base}. This trend
belies a \textit{fundamental} divide in the design space of database
systems: the need for synchronous coordination between concurrent
operations. On the one hand, ``strong'' data consistency (i.e., CAP
``CP''~\cite{gilbert-cap}) models such as the gold standard of
traditional database concurrency control---the serializable
transaction, guaranteeing ``single system image''
behavior~\cite{gray-virtues}---provide semantic guarantees that are
useful for programmers~\cite{bernstein-book}. However, these
``strong'' models require synchronous coordination across replicas in
order to provide a safe response, leading to provable unavailability
and increased latency, and, in a single-site context, possible stalls
during execution~\cite{pacelc}. In contrast, ``weak consistency''
(i.e., CAP ``AP'', or ``highly available''~\cite{gilbert-cap}) models
provide a subset of the semantic guarantees but do not require
synchronous coordination and therefore do not suffer from
unavailability or latency~\cite{hat-vldb}. The latter category of
models (and many of their implementations~\cite{swift}) defer
coordination until some future point~\cite{calm,consistency-borders}
and are therefore are perfectly scalable, even at the granularity of
an individual database record. However, in giving up semantic
guarantees, weak isolation models sacrifice intuitive programmability.

This provable trade-off between semantics and coordination leads
programmers to a difficult choice. On the one hand, many applications
cannot operate correctly without serializable or Snapshot Isolation
guarantees. However, on the other hand, many applications---whether
running on newfangled stores providing weak data consistency or under
traditional ``weak isolation'' guarantees~\cite{adya-isolation}---seem
to tolerate weaker guarantees. Ideally, users can choose the weakest
possible set of semantics and still maintain correctness, but this is
no easy task: programmers today must manually map their
application-level consistency concerns to low-level models expressed
via constructs like admissible traces of reads and writes. This in
turn requires developers to become experts in distributed data
consistency, weak isolation, and replication
protocols~\cite{consistency-borders}.

In this paper, we seek an alternative approach that allows users to
determine when it is provably \textit{necessary} to employ
coordination in order to maintain application-level
correctness. Foregoing synchronous coordination (and therefore
serializability) necessarily means that users will be exposed to
isolation \textit{anomalies} resulting from concurrent
access. Determining which anomalies matter to an application is
impossible if a database system has no knowledge of the
application. Accordingly, we consider a model in which users
explicitly provide the database with \textit{integrity constraints},
or predicates representing application-level consistency that should
always be satisfied by the database state. Given these constraints,
the database can determine which procedures will require synchronous
coordination and, often, which read/write data consistency and
isolation level each procedure requires. We prove that the
\textit{\fullnameconfluence} property
(\iconfluence)~\cite{obs-confluence}---informally, the ability to
merge isolated transaction executions without violating
constraints---is a necessary and sufficient condition for executing
with \cfreedom. While we believe that this is the first necessary and
sufficient condition for availability without coordination, our
results leverage several decades-old concepts from the database
literature, including semantics-based concurrency
control~\cite{sdd1,decomp-semantics,badrinath-semantics,garciamolina-semantics,korth-serializability}
synchronization for abstract data
types~\cite{herlihy-apologizing,weihl-thesis}, and nested atomic
transactions~\cite{atomictransactions}
(Section~\ref{sec:relatedwork}).

This theory provides a foundation for \textit{coordination-avoiding
  databases}: systems that coordinate only when necessary.  If a
coordination-avoiding database system coordinates, it is because
application consistency \textit{cannot} be guaranteed without doing
so. Accordingly, coordination-avoidance analysis directly captures the
scalability of a given application: an application with \cfreedom can
effectively scale infinitely with the addition of more machines, while
the degree to which conflicts are distributed directly determines an
application's ability to scale out and up. We pithily summarize the
philosophy of coordination-avoidance via two high-level principles:
\begin{introenumerate}
\item \textit{Let concurrency safely flourish}: if a user's operations
  are \iconfluent, they should be executed on separate copies of
  database state, without coordination.
\item \textit{Minimize the distribution (both in space and time) of
  conflicting operations}: if a user's operations do not commute,
  execute the conflicting sections while involving as few servers and
  with as short of a critical section as possible.
\end{introenumerate}
To illustrate the utility of these principles, we embody \iconfluence
analysis in a tiny language, \lang, and analyze applications for
\cfreedom. As a proof of concept, we analyze and implement the TPC-C
New-Order on a coordination-avoiding database prototype and achieve
linear scalability to over 1.8 million transactions per second on a
100-node EC2 cluster (nearly four times the current record held by
Oracle). Our prototype's competitive advantage is not due to
bleeding-edge performance-oriented engineering but is instead due to
theoretically-motivated, judicious use of coordination.

Overall, this paper attempts to improve distributed database
programmability by unifying industry trends with the collected wisdom
of the database community. We recognize the scalability advantages of
weakly consistent data stores but reconcile them with the
programmability benefits of maintaining traditional ACID Consistency
on behalf of application designers. In doing so, we place an
additional burden on programmers, who must either provide the database
with a complete and machine-interpretable specification of
application-level invariants or otherwise must perform analysis
themselves and manually label their transactions. For programmers that
wish to achieve their application's maximum scalability, we believe
that both of these alternatives are far preferable to the
state-of-the-art ad-hoc mapping from application-level ACID
Consistency to distributed data consistency models performed today. We
accordingly view this work as the first step in revisiting core
database concepts like query optimization, failure recovery, and data
layout in light of increased knowledge of application-level semantics.
